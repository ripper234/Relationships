\documentclass{article}
\usepackage{amsfonts}
\usepackage{amssymb}
\newcommand{\field}[1]{\mathbb{#1}}
\newcommand{\reals}{\field{R}}
\newcommand{\nats}{\field{N}}
\title{Quantifying Love}
\author{Ron Gross}
\date{May 25, 2006}

\begin{document}

\maketitle

There is much work in the literature that assumes a known quantification of love
("you don't love me enough", "you love her more than you love me", etc...). This papers attempts to quantify
the term "love".

Let $P$ be a set of love-capable agents \footnote{we will focus our discussion on people, but other 
entities are assumed to be able to show "love" as well} and $U$ be a set of variables.
The variables in $U$ need not be of any one domain ("money in bank account X" and "person Y's physical well being"
are examples of such variables). A state $s$ is an assignment to every variable in $U$.
Let $S$ denote the set of states.
A "happiness function" is a function
$\phi:S\rightarrow [0, 1]$. For simplicity, we take the set of time points to be the discreet $\nats$, although
other choices such as $\reals$ could be justified as well. The target $[0, 1]$ was chosen to simplify comparison
between different people's happiness function.

We assume that for every person $p$, his goal in life is to maximize the expression
$\Phi_p\triangleq \Sigma_{t=0}^{T}\phi_p(s_t)$, where $T$ is his moment of death, $\phi_p$ is his happiness
function, and $\{s_0\dots s_T\}$ are the states during his lifetime (we choose $t=0$ as the moment of his birth).
It can be argued that a person's happiness function may change over time - for example, he may
like apples and hate oranges when he is young, and switch tastes when he gets older. We don't investigate 
this point further and assume that it if at all, the happiness function changes only very slowly, and
is considered fixed in our analysis.

The universe $U$ can be decomposed into $U^I$, the internal variables (including
a person's well being, sense of taste, bank account) and $U^E$, the external variables relative to person $p$. 
A state $s_t$ is similarly decomposed into $s_t^I$ and $s_t^E$
We will assume such a decomposition of $U$ into external and internal variables exist,
though defining one might not be an easy problem. Furthermore, we assume a composition function $f_p$ exists,
so that $\phi_p(s_t) = f_p(\phi_p^I(s_t^I), \phi_p^E(s_t^E))$, and $f_p$ is a monotonically increasing function.

Let $\phi_{(p,q)}$ be $p$'s estimates on $q$'s happiness function. That is, $\phi_{(p, q)}$ is $p's$ approximation
of $\phi_q$.
We define a person's {\em love function} as a function $l_p:P\setminus \{p\}\rightarrow \reals$ so that 
$\phi_p^E(s_t^E)=\Sigma_{q\ne p} l(q)\phi_{(p,q)}(s_t)$. We assume here that the external happiness $\phi_p^E$ is
determined solely by the happiness function of all other people, though this could be extended to include
other factors as well. Note that for a given other $q$, if $l_p(q)=0$ then $p$ does not care at all about
$q$'s happiness, and if $l_p(q)<0$ then $p$ likes it when he thinks $q$ suffers. For most people $p$ and $q$, 
$l_p(q)$ is very nearly 0, as there is very little interaction (perhaps maybe for Jesus Christ or other saints
it is different).

Cooperation is a useful strategy in maximizing $\Phi_p$. Suppose $l_p(q) \ge 0$, and let's say $p$ thinks
$q$ is reliable, regardless of his other properties. And let us say $p$ at moment $t$ can choose between two
different actions $A$ and $B$. Let $S_A$ be the state if $A$ is taken, and $S_B$ be the state if $B$ is taken.
Suppose $\phi_p^I(A) < \phi_p^I(B)$ and $\phi_(p, q)(A)-\phi_(p, q)(B) > \phi_p^I(B) - \phi_p^I(A)$. 
Then by choosing to take action $A$ over $B$, $p$ ensures $q$'s happiness increases by more than his own would by choosing $A$.
If at some
later point $t'$ person $q$ does the same, the overall benefit for both $p$ and $q$ is greater than by greedily
choosing the currently better option $B$. Note that if $p$ hates $q$ and $l_p(q)<0$, this may no longer be
a wise strategy - helping $q$ might lower $p$'s own happiness further, does making the deal a non profitable one.
On the other hand, if $l_p(q)>>0$ (for example, $l_p(q)=0.5$), then it might benefit $p$ to help $q$ even at a great
personal expense, and not just for the promise of future rewards. $p$ benefits from helping $q$ because 
he feels happier when $q$ is, so part of the cost on $p$'s part is negated by this.

If $l_p(q)=1$, then $p$ values $q$'s happiness as much as their own. Examples exist when $l_p(q)>1$, for example
mothers are known to suffer for their babies - of course enjoying it overall because the positive effect 
of their babies' happiness on their own. Pathological cases of $l_p(q) >>1$ are considered psychologically unhealthy,
as $p$ cares more for $q$ than for himself and will be severely disappointed if his love function change later on,
because his own personal happiness $\phi_p^I$ is presumably very low because of altruistic choices he has made to increase $q$'s
happiness. Another danger is a bad approximation of $l_q$ by $p$. If $\phi_(p,q)$ is very different from $\phi_p$,
then the described strategy of mutual helping will fail, as $q$ will not feel inclined to help $p$ 
since $p$'s actions increased $\phi_(p,q)$ but not $\phi_q$.
It would be interesting to find if 
friends and acquaintances have $l$ somewhere around $0.5$ or some other number roughly in the middle of $[0,1]$.
This author consider an ideal relationship of any kind to have $l=1$, where one considers the other person's
happiness just as highly as he considers his. That ideal is probably hardly ever realized in this world,
but one can still hope.
\end{document}
